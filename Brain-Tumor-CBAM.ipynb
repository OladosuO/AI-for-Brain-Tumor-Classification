{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a331931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import imageio\n",
    "import scipy, scipy.misc, scipy.signal\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "def build_is_hist(img):\n",
    "    hei = img.shape[0]\n",
    "    wid = img.shape[1]\n",
    "    ch = img.shape[2]\n",
    "    Img = np.zeros((hei+4, wid+4, ch))\n",
    "    for i in range(ch):\n",
    "        Img[:,:,i] = np.pad(img[:,:,i], (2,2), 'edge')\n",
    "    hsv = (matplotlib.colors.rgb_to_hsv(Img))\n",
    "    hsv[:,:,0] = hsv[:,:,0] * 255\n",
    "    hsv[:,:,1] = hsv[:,:,1] * 255\n",
    "    hsv[hsv>255] = 255\n",
    "    hsv[hsv<0] = 0\n",
    "    hsv = hsv.astype(np.uint8).astype(np.float64)\n",
    "    fh = np.array([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])\n",
    "    fv = fh.conj().T\n",
    "    \n",
    "    H = hsv[:,:,0]\n",
    "    S = hsv[:,:,1]\n",
    "    I = hsv[:,:,2]\n",
    "\n",
    "    dIh = scipy.signal.convolve2d(I, np.rot90(fh, 2), mode='same')\n",
    "    dIv = scipy.signal.convolve2d(I, np.rot90(fv, 2), mode='same')\n",
    "    dIh[dIh==0] = 0.00001\n",
    "    dIv[dIv==0] = 0.00001\n",
    "    dI = np.sqrt(dIh**2+dIv**2).astype(np.uint32)\n",
    "    di = dI[2:hei+2,2:wid+2]\n",
    "    \n",
    "    dSh = scipy.signal.convolve2d(S, np.rot90(fh, 2), mode='same')\n",
    "    dSv = scipy.signal.convolve2d(S, np.rot90(fv, 2), mode='same')\n",
    "    dSh[dSh==0] = 0.00001\n",
    "    dSv[dSv==0] = 0.00001\n",
    "    dS = np.sqrt(dSh**2+dSv**2).astype(np.uint32)\n",
    "    ds = dS[2:hei+2,2:wid+2]\n",
    "\n",
    "    \n",
    "    h = H[2:hei+2,2:wid+2]\n",
    "    s = S[2:hei+2,2:wid+2]\n",
    "    i = I[2:hei+2,2:wid+2].astype(np.uint8)\n",
    "    \n",
    "    Imean = scipy.signal.convolve2d(I,np.ones((5,5))/25, mode='same')\n",
    "    Smean = scipy.signal.convolve2d(S,np.ones((5,5))/25, mode='same')\n",
    "    \n",
    "    Rho = np.zeros((hei+4,wid+4))\n",
    "    for p in range(2,hei+2):\n",
    "        for q in range(2,wid+2):\n",
    "            tmpi = I[p-2:p+3,q-2:q+3]\n",
    "            tmps = S[p-2:p+3,q-2:q+3]\n",
    "            corre = np.corrcoef(tmpi.flatten('F'),tmps.flatten('F'))\n",
    "            Rho[p,q] = corre[0,1]\n",
    "    \n",
    "    rho = np.abs(Rho[2:hei+2,2:wid+2])\n",
    "    rho[np.isnan(rho)] = 0\n",
    "    rd = (rho*ds).astype(np.uint32)\n",
    "    Hist_I = np.zeros((256,1))\n",
    "    Hist_S = np.zeros((256,1))\n",
    "    \n",
    "    for n in range(0,255):\n",
    "        temp = np.zeros(di.shape)\n",
    "        temp[i==n] = di[i==n]\n",
    "        Hist_I[n+1] = np.sum(temp.flatten('F'))\n",
    "        temp = np.zeros(di.shape)\n",
    "        temp[i==n] = rd[i==n]\n",
    "        Hist_S[n+1] = np.sum(temp.flatten('F'))\n",
    "\n",
    "    return Hist_I, Hist_S\n",
    "\n",
    "def dhe(img, alpha=0.5):\n",
    "    \n",
    "    hist_i, hist_s = build_is_hist(img)\n",
    "    hist_c = alpha*hist_s + (1-alpha)*hist_i\n",
    "    hist_sum = np.sum(hist_c)\n",
    "    hist_cum = hist_c.cumsum(axis=0)\n",
    "    \n",
    "    hsv = matplotlib.colors.rgb_to_hsv(img)\n",
    "    h = hsv[:,:,0]\n",
    "    s = hsv[:,:,1]\n",
    "    i = hsv[:,:,2].astype(np.uint8)\n",
    "    \n",
    "    c = hist_cum / hist_sum\n",
    "    s_r = (c * 255)\n",
    "    i_s = np.zeros(i.shape)\n",
    "    for n in range(0,255):\n",
    "        i_s[i==n] = s_r[n+1]/255.0\n",
    "    i_s[i==255] = 1\n",
    "    hsi_o = np.stack((h,s,i_s), axis=2)\n",
    "    result = matplotlib.colors.hsv_to_rgb(hsi_o)\n",
    "    \n",
    "    result = result * 255\n",
    "    result[result>255] = 255\n",
    "    result[result<0] = 0\n",
    "    return result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27756253",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE= 224\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "train_dhe=[]\n",
    "for directory_path in glob.glob(\"brain-tumor\\\\Training\\\\*\"):\n",
    "#for directory_path in \"/content/drive/My Drive/dataset/images/validation/*\":\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "    #for img_path in directory_path, \"*.jpg\":\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        #try:\n",
    "        img = cv2.resize(img, (SIZE,SIZE))\n",
    "\n",
    "\n",
    "\n",
    "        img = image.img_to_array(img)\n",
    "        ## CLAHE dosu\n",
    "        img = img.astype(np.uint8)\n",
    "        #lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l,a,b = cv2.split(lab_img)\n",
    "        equ = cv2.equalizeHist(l)\n",
    "        updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "        hist_eq_img = cv2.cvtColor(updated_lab_img1,cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "        ##Apply CLAHE to Lchannel\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0,tileGridSize=(8,8))\n",
    "        clahe_img = clahe.apply(l)\n",
    "    \n",
    "        ## combine the CLAHE\n",
    "        updated_lab_img2 =cv2.merge((clahe_img,a,b))\n",
    "    \n",
    "        ## convert LAB\n",
    "        CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "        #####result = dhe(img) \n",
    "    \n",
    "        #except:\n",
    "        #break\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        ####train_dhe.append(result)\n",
    "        train_images.append(CLAHE_img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "###train_dhe = np.array(train_dhe)\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa571d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE= 224\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for directory_path in glob.glob(\"brain-tumor\\\\Testing\\\\*\"):\n",
    "#for directory_path in \"/content/drive/My Drive/dataset/images/validation/*\":\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "    #for img_path in directory_path, \"*.jpg\":\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        #try:\n",
    "        img = cv2.resize(img, (SIZE,SIZE))\n",
    "\n",
    "\n",
    "\n",
    "        img = image.img_to_array(img)\n",
    "        ## CLAHE dosu\n",
    "        img = img.astype(np.uint8)\n",
    "        #lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l,a,b = cv2.split(lab_img)\n",
    "        equ = cv2.equalizeHist(l)\n",
    "        updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "        hist_eq_img = cv2.cvtColor(updated_lab_img1,cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "        ##Apply CLAHE to Lchannel\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0,tileGridSize=(8,8))\n",
    "        clahe_img = clahe.apply(l)\n",
    "    \n",
    "        ## combine the CLAHE\n",
    "        updated_lab_img2 =cv2.merge((clahe_img,a,b))\n",
    "    \n",
    "        ## convert LAB\n",
    "        CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    \n",
    "        #except:\n",
    "        #break\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(CLAHE_img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8066f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels_encoded\n",
    "yv_test = test_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x2_test, y_train,  y_test = train_test_split(train_images, train_labels_encoded, random_state=20, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a62923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise pixel values to between 0 and 1\n",
    "x_train, x2_test, xv_test = x_train /255.0, x2_test / 255.0, test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "yv_test_one_hot = to_categorical(yv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(SIZE,SIZE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03503",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_resnettr = preprocess_input(x_train)\n",
    "prep_resnette = preprocess_input(x2_test)\n",
    "prep_v = preprocess_input(xv_test)\n",
    "\n",
    "resnet_trfeature = resnet_model.predict(prep_resnettr)\n",
    "resnet_tefeature = resnet_model.predict(prep_resnette)\n",
    "resnet_v = resnet_model.predict(prep_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159cde91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501856d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    # Channel attention\n",
    "    channels = inputs.shape[-1]\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(units=int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(units=channels, activation='relu', use_bias=True)\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs\n",
    "\n",
    "\n",
    "def ResNet50_CBAM():\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    # Create the ResNet50 model\n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Add the CBAM attention mechanism\n",
    "    x = resnet50.output\n",
    "    x = cbam_block(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(units=4, activation='sigmoid')(x)\n",
    "\n",
    "    # Combine the ResNet50 model and the attention mechanism\n",
    "    model = models.Model(inputs=resnet50.input, outputs=x, name='ResNet50_CBAM')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8775f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet50 model with added CBAM\n",
    "def ResNet50_CBAM():\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # Create the ResNet50 model\n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Add the CBAM attention mechanism\n",
    "    x = layers.GlobalAveragePooling2D()(resnet50.output)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    #x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    #x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    #x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Reshape((1, 1, 128))(x)\n",
    "    x_max = layers.GlobalMaxPooling2D()(x)\n",
    "    x_avg = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Concatenate()([x_max, x_avg])\n",
    "    x = layers.Dense(units=4,activation='sigmoid')(x)\n",
    "    \n",
    "    # Combine the ResNet50 model and the attention mechanism\n",
    "    model = models.Model(inputs=resnet50.input, outputs=x, name='ResNet50_CBAM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a1941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50_CBAM()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_dhe, train_labels_encoded, epochs=20, batch_size=32, validation_data=(test_dhe, test_labels_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a5f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3875336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fa5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
